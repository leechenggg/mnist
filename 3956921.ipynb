{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.上传本地数据集，导入相关包\n",
    "-----\n",
    "在./work上上传mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 安装VisualDL\r\n",
    "!pip install --upgrade --pre visualdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入相关包\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import json\r\n",
    "import gzip\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "from PIL import Image\r\n",
    "from paddle.static import InputSpec\r\n",
    "#引入VisualDL库，并设定保存作图数据的文件位置\r\n",
    "from visualdl import LogWriter\r\n",
    "log_writer = LogWriter(logdir=\"./log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.数据处理\n",
    "----\n",
    "对mnisi数据集进行处理并封装成函数形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\r\n",
    "    # 定义数据集路径\r\n",
    "    data_file = \"/home/aistudio/data/data145337/mnist.json.gz\"\r\n",
    "    print(\"loading dataset from {}\".format(data_file))\r\n",
    "    data = json.load(gzip.open(data_file))\r\n",
    "    # 读取数据集中的训练集，验证集和测试集\r\n",
    "    train_set, val_set, test_set = data\r\n",
    "    # 数据集相关参数\r\n",
    "    IMG_ROWS = 28\r\n",
    "    IMG_COLS = 28\r\n",
    "\r\n",
    "    # 根据mode参数来选择方式\r\n",
    "    if mode == 'train':\r\n",
    "        images = train_set[0]\r\n",
    "        labels = train_set[1]\r\n",
    "    elif mode == 'val':\r\n",
    "        images = val_set[0]\r\n",
    "        labels = val_set[1]\r\n",
    "    elif mode == 'test':\r\n",
    "        images = test_set[0]\r\n",
    "        labels = test_set[1]\r\n",
    "\r\n",
    "    # 验证图片数量和标签数是否一致\r\n",
    "    images_length = len(images)\r\n",
    "    assert images_length == len(labels)\r\n",
    "    print(\"length of train_images{} should be the same as labels{}\".format(images_length, len(labels)))\r\n",
    "\r\n",
    "    # 定义index_list为处理数据准备\r\n",
    "    index_list = list(range(images_length))\r\n",
    "    # 定义BATCHSIZE\r\n",
    "    BATCHSIZE = 100\r\n",
    "\r\n",
    "    # 定义数据生成器\r\n",
    "    def data_generator():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(index_list)\r\n",
    "        images_list = []\r\n",
    "        labels_list = []\r\n",
    "        for i in index_list:\r\n",
    "            img = np.reshape(images[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\r\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\r\n",
    "            images_list.append(img)\r\n",
    "            labels_list.append(label)\r\n",
    "            # 如果image_list达到一个batchsize则返回一个批次数据\r\n",
    "            if len(images_list) == BATCHSIZE:\r\n",
    "                yield np.array(images_list), np.array(labels_list)\r\n",
    "                # 清空数据列表\r\n",
    "                images_list = []\r\n",
    "                labels_list = []\r\n",
    "\r\n",
    "        # 如果剩余数量小于100，则返回剩余数据\r\n",
    "        if len(images_list) > 0:\r\n",
    "            yield np.array(images_list), np.array(labels_list)\r\n",
    "\r\n",
    "    return data_generator\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 定义模型结构\n",
    "----\n",
    "通过MNIST类构建模型属性，以及模型方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /home/aistudio/data/data145337/mnist.json.gz\n",
      "length of train_images50000 should be the same as labels50000\n"
     ]
    }
   ],
   "source": [
    "# 定义模型结构\r\n",
    "class MNIST(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MNIST, self).__init__()\r\n",
    "\r\n",
    "        # 定义卷积层和池化层以及最后的全连接层，输出特征通道为20，卷积核的大小为5，卷积步长为1，padding为2\r\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\r\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\r\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\r\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\r\n",
    "        self.fc = Linear(in_features=980, out_features=10)\r\n",
    "\r\n",
    "        # 定义前向计算过程\r\n",
    "    @paddle.jit.to_static  # 添加装饰器，使动态图网络结构在静态图模式下运行\r\n",
    "    def forward(self, inputs, label):\r\n",
    "        x = self.conv1(inputs)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.max_pool1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.max_pool2(x)\r\n",
    "        x = paddle.reshape(x, [x.shape[0], 980])\r\n",
    "        x = self.fc(x)\r\n",
    "        if label is not None:\r\n",
    "            acc = paddle.metric.accuracy(input=x, label=label)\r\n",
    "            return x, acc\r\n",
    "        else:\r\n",
    "            return x\r\n",
    "\r\n",
    "\r\n",
    "# 调用load_data函数\r\n",
    "train_loader = load_data('train')\r\n",
    "# 使用GPU进行训练\r\n",
    "# use_gpu = True\r\n",
    "# paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.封装训练函数以及进行模型训练\n",
    "____\n",
    "训练之后保存模型结构和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [2.68310571]), acc is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.09000000])\n",
      "epoch: 0, batch: 200, loss is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.05868373]), acc is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.98000002])\n",
      "epoch: 0, batch: 400, loss is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.03520438]), acc is Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.99000001])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_93/1318353594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# 启动训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_93/1318353594.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# 前向计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# 利用交叉熵损失函数计算loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;31m# 4. return outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpartial_program_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/partial_program.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_scope_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_double_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             *attrs)\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_scope_if_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mrestored_nest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 封装训练函数\r\n",
    "def train(model):\r\n",
    "    model = MNIST()\r\n",
    "    model.train()\r\n",
    "    # 使用随机梯度下降SGD优化算法\r\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\r\n",
    "\r\n",
    "    # 定义迭代轮数\r\n",
    "    epoch_num = 5\r\n",
    "    iter = 0\r\n",
    "    for epoch_id in range(epoch_num):\r\n",
    "        # 每训练一轮就保存一轮模型结构\r\n",
    "        # paddle.save(model.state_dict(), './mnist.pdparams {}'.format(epoch_id))\r\n",
    "        # print('model has been saved in ./mnist.pdparams')\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            images, labels = data\r\n",
    "            images = paddle.to_tensor(images)\r\n",
    "            labels = paddle.to_tensor(labels)\r\n",
    "\r\n",
    "            # 前向计算\r\n",
    "            predicts, acc = model(images, labels)\r\n",
    "            # 利用交叉熵损失函数计算loss\r\n",
    "            loss = F.cross_entropy(predicts, labels)\r\n",
    "            avg_loss = paddle.mean(loss)\r\n",
    "\r\n",
    "            # 每训练200批次数据，就打印当前loss情况\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print('epoch: {}, batch: {}, loss is {}, acc is {}'.format(epoch_id, batch_id, avg_loss, acc))\r\n",
    "                log_writer.add_scalar(tag = 'acc', step = iter, value = acc.numpy())\r\n",
    "                log_writer.add_scalar(tag = 'loss', step = iter, value = avg_loss.numpy())\r\n",
    "                iter = iter + 100\r\n",
    "\r\n",
    "            # 后向传播更新参数消除梯度\r\n",
    "            avg_loss.backward()\r\n",
    "            opt.step()\r\n",
    "            opt.clear_grad()\r\n",
    "\r\n",
    "    # 保存模型参数\r\n",
    "    paddle.save(model.state_dict(), './best_mnist.pdparams')\r\n",
    "    print(\"trained model_params has been saved\")\r\n",
    "    # 保存inference模型结构，可用于部署\r\n",
    "    paddle.jit.save(\r\n",
    "    layer=model,\r\n",
    "    path=\"inference/mnist\")\r\n",
    "    print(\"==>Inference model saved in inference/mnist.\")\r\n",
    "\r\n",
    "\r\n",
    "# 启动训练\r\n",
    "model = MNIST()\r\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.模型评估\n",
    "---\n",
    "使用test测试数据集进行模型评估，计算多个batch的平均损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluation......\n",
      "loading dataset from /home/aistudio/data/data145337/mnist.json.gz\n",
      "length of train_images10000 should be the same as labels10000\n",
      "loss=0.06793506548141522, acc=0.9807000070810318\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model):\r\n",
    "    print(\"start evaluation......\")\r\n",
    "    # 确定模型参数路径\r\n",
    "    model_params_path = \"best_mnist.pdparams\"\r\n",
    "    # 加载模型参数\r\n",
    "    param_dict = paddle.load(model_params_path)\r\n",
    "    model.load_dict(param_dict)\r\n",
    "    model.eval()\r\n",
    "    test_loader = load_data('test')\r\n",
    "\r\n",
    "    acc_set = []\r\n",
    "    avg_loss_set = []\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        images, labels = data\r\n",
    "        images = paddle.to_tensor(images)\r\n",
    "        labels = paddle.to_tensor(labels)\r\n",
    "\r\n",
    "        # 前向计算\r\n",
    "        predicts, acc = model(images, labels)\r\n",
    "        # 利用交叉熵损失函数计算loss\r\n",
    "        loss = F.cross_entropy(predicts, labels)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "        acc_set.append(float(acc.numpy()))\r\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\r\n",
    "\r\n",
    "    # 计算多个batch的平均损失和准确率\r\n",
    "    acc_val_mean = np.array(acc_set).mean()\r\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\r\n",
    "\r\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\r\n",
    "\r\n",
    "model = MNIST()\r\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6.可视化分析\n",
    "----\n",
    "VisualDL是飞桨可视化分析工具，以丰富的图表呈现训练参数变化趋势、模型结构、数据样本、高维数据分布等。帮助用户清晰直观地理解深度学习模型训练过程及模型结构，进而实现高效的模型调优。以下是可视化图形![](https://ai-studio-static-online.cdn.bcebos.com/f0b9e6317d6e4987a17c3f0587ddaad4c7086526e22146e2b9cc38677685de00)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f45863b8f45f40538b14777dc1312f44fc84e4ee81a744b99b1b50e1f2ec4a77)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7.传入一张手写数字图片进行测试\n",
    "---\n",
    "自己动手写一个数字来感受一下模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "图像预处理处理以及显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取一张本地的样例图片，转变成模型输入的格式\r\n",
    "def load_image(img_path):\r\n",
    "    # 从img_path中读取图像，并转为灰度图\r\n",
    "    im = Image.open(img_path).convert('L')\r\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\r\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)\r\n",
    "    # 图像归一化,识别黑底白字不需要归一化处理\r\n",
    "    # im = im / 255.0 * 2.0 - 1.0\r\n",
    "    return im\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_path='work/t4.png'\r\n",
    "img = Image.open(infer_path)\r\n",
    "plt.imshow(img)   #根据数组绘制图像\r\n",
    "plt.show()        #显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次预测的数字是:  4\n"
     ]
    }
   ],
   "source": [
    "# 定义预测过程\r\n",
    "model = MNIST()\r\n",
    "params_file_path = 'best_mnist.pdparams'\r\n",
    "img_path = 'work/t4.png'\r\n",
    "# 加载模型参数\r\n",
    "param_dict = paddle.load(params_file_path)\r\n",
    "model.load_dict(param_dict)\r\n",
    "# 灌入数据\r\n",
    "model.eval()\r\n",
    "im = load_image(img_path)\r\n",
    "#模型反馈10个分类标签的对应概率\r\n",
    "results = model(paddle.to_tensor(im), label=None)\r\n",
    "#取概率最大的标签作为预测输出\r\n",
    "lab = np.argsort(results.numpy())\r\n",
    "print(\"本次预测的数字是: \", lab[0][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
